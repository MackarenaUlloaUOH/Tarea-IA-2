# -*- coding: utf-8 -*-
"""Tarea2_IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qbLSIlHFkaKhQZT39kL_gFpCDyo-EVZ-

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Mackarena Evarista Ulloa Jara

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

# Subir archivos

Cargaremos el dataset de forma remota con `wget` desde un repositorio de GitHub. Así podremos acceder al dataset solo con ejecutar las siguientes lineas, ya que este descarga los archivos directamente en el ambiente de Colab
"""

from google.colab import drive
drive.mount('/content/drive')

#Importar librerias
import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score

"""## Subir datasets de dígitos (train)"""

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt  # importo 1_digits_train.txt

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt   # importo 1_digits_test.txt

"""## Leer dataset de dígitos"""

column_names = ["feat" + str(i) for i in range(64)] #Crea una lista
column_names.append("class")

df1_val = pd.read_csv('1_digits_train.txt', names = column_names)
df1_val

df2 = pd.read_csv('1_digits_test.txt', names = column_names)
df2

"""## Dividimos los datos de entrenamiento en validación y entrenamiento"""

#Dividir en conjuntos el data 1
df1, df_val = train_test_split(df1_val, test_size = 0.3, random_state = 10)
print("Muestras de entrenamiento: ", len(df1))
print("Muestras de validación: ", len(df_val))
print("Muestras de prueba: ", len(df2))
print("Muestras totales: ", len(df1_val)+len(df2))

"""## Normalización de los datos"""

#Estandarización en las primeras 64 columnas
scaler = StandardScaler().fit(df1.iloc[:,0:64])
df1.iloc[:,0:64] = scaler.transform(df1.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df2.iloc[:,0:64] = scaler.transform(df2.iloc[:,0:64])

df1

"""## Crear datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats1 = df1.to_numpy()[:, 0:64].astype(np.float32)
labels1 = df1.to_numpy()[:, 64].astype(int)
dataset1 = [{"features": feats1[i, :], "labels": labels1[i]} for i in range(feats1.shape[0])]

feats_val = df_val.to_numpy()[:, 0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:, 64].astype(int)
dataset_val = [{"features": feats_val[i, :], "labels": labels_val[i]} for i in range(feats_val.shape[0])]

feats2 = df2.to_numpy()[:, 0:64].astype(np.float32)
labels2 = df2.to_numpy()[:, 64].astype(int)
dataset2 = [{"features": feats2[i, :], "labels": labels2[i]} for i in range(feats2.shape[0])]

# Crear dataloaders
dataloader1 = torch.utils.data.DataLoader(dataset1, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader2 = torch.utils.data.DataLoader(dataset2, batch_size=128, shuffle=True, num_workers=0)

"""## Crear modelo"""

#Casos
#Caso (a)
model_a = nn.Sequential(
    nn.Linear(64, 10),
    nn.ReLU(),
    nn.Linear(10, 10)       #Una capa
)

#Caso (b)
model_b = nn.Sequential(
    nn.Linear(64, 40),
    nn.ReLU(),
    nn.Linear(40, 10)       #Una capa
)

#Caso (c)
model_c = nn.Sequential(
    nn.Linear(64, 10),
    nn.Tanh(),
    nn.Linear(10, 10)       #Una capa
)

#Caso (d)
model_d = nn.Sequential(
    nn.Linear(64, 40),
    nn.Tanh(),
    nn.Linear(40, 10)      #Una capa
)

#Caso (e)
model_e = nn.Sequential(
    nn.Linear(64, 10),
    nn.ReLU(),
    nn.Linear(10, 10),
    nn.ReLU(),
    nn.Linear(10, 10)      #Dos capas
)


#Caso (f)
model_f = nn.Sequential(
    nn.Linear(64, 40),
    nn.ReLU(),
    nn.Linear(40, 40),
    nn.ReLU(),
    nn.Linear(40, 10)      #Dos capas
)

device = torch.device('cuda')

#Caso (a)
model_a = model_a.to(device)
criterion_a = nn.CrossEntropyLoss()
optimizer_a = torch.optim.Adam(model_a.parameters(), lr=1e-3)

#Caso (b)
model_b = model_b.to(device)
criterion_b = nn.CrossEntropyLoss()
optimizer_b = torch.optim.Adam(model_b.parameters(), lr=1e-3)

#Caso (c)
model_c = model_c.to(device)
criterion_c = nn.CrossEntropyLoss()
optimizer_c = torch.optim.Adam(model_c.parameters(), lr=1e-3)

#Caso (d)
model_d = model_d.to(device)
criterion_d = nn.CrossEntropyLoss()
optimizer_d = torch.optim.Adam(model_d.parameters(), lr=1e-3)

#Caso (e)
model_e = model_e.to(device)
criterion_e = nn.CrossEntropyLoss()
optimizer_e = torch.optim.Adam(model_e.parameters(), lr=1e-3)

#Caso (f)
model_f = model_f.to(device)
criterion_f = nn.CrossEntropyLoss()
optimizer_f = torch.optim.Adam(model_f.parameters(), lr=1e-3)

"""## P2: Entrenamiento

###Caso a
"""

#Entrenamiento del modelo (a) con early stopping
start_time = time.time()

#Guardar resultados del loss y épocas que duró el entrenamiento
loss_train_a = []
loss_val_a = []
epochs_a = []

#Configurar early stopping con paciencia
best_val_loss_a = float('inf')
max_epochs_a = 1000
early_stopping_patience = 10  #Número de epochs para esperar antes de detener el entrenamiento si el loss de validación aumenta

# ------------------Entrenamiento de la red por 1000 épocas------------------ #
for epoch in range(max_epochs_a):

  # Guardar loss de cada batch
  loss_train_batches_a = []
  loss_val_batches_a = []

  # ------------------Entrenamiento------------------ #
  model_a.train()

  # Recorremos cada lote de los datos (batch)
  for i, data in enumerate(dataloader1, 0):
      # Procesar batch actual
      inputs = data["features"].to(device)    # Características
      labels = data["labels"].to(device)      # Clases
      optimizer_a.zero_grad()                 # Poner a cero los gradientes de los parámetros
      # forward + backward + optimize
      outputs = model_a(inputs)               # Predicciones
      loss_a = criterion_a(outputs, labels)   # Loss de entrenamiento
      loss_a.backward()                       # Backpropagation
      optimizer_a.step()

      # La pérdida de entrenamiento en el batch actual
      loss_train_batches_a.append(loss_a.item())

  # El loss de entrenamiento de la época actual
  mean_train_loss_a = np.mean(loss_train_batches_a)
  loss_train_a.append(mean_train_loss_a) # Loss promedio de los batches

  # ------------------Validación------------------ #
  model_a.eval()

  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
        # batch actual
        inputs = data["features"].to(device)  # Características
        labels = data["labels"].to(device)    # Clases
        outputs = model_a(inputs)             # Obteniendo predicciones

        # La pérdida de validación en el batch actual
        loss_a = criterion_a(outputs, labels)
        loss_val_batches_a.append(loss_a.item())

  # El Loss de validación de la época actual
  mean_val_loss_a = np.mean(loss_val_batches_a)
  loss_val_a.append(mean_val_loss_a)         # Loss promedio de los batches

  # Guardar la época
  epochs_a.append(epoch)

  # Verificar si el loss de validación está aumentando
  if mean_val_loss_a < best_val_loss_a:
      best_val_loss_a = mean_val_loss_a
      patience_counter = 0  # Reiniciar el contador de paciencia
  else:
      patience_counter += 1

  # Imprimir loss de entrenamiento y validación
  print('Epoch %d: Training Loss: %.5f, Validation Loss: %.5f' % (epoch, mean_train_loss_a, mean_val_loss_a))

  # Detener si el loss de validación no mejora
  if patience_counter >= early_stopping_patience:
      print('Detención anticipada debido al aumento de la pérdida de validación.')
      print('Early stopping at epoch', epoch)
      break

end_time = time.time()
print('Finished Training (Caso A), total time: %.2f seconds' % (end_time-start_time))

# Graficar el loss de entrenamiento y validación en función del tiempo
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(epochs_a, loss_train_a, 'b', label='Entrenamiento')
plt.plot(epochs_a, loss_val_a, 'r', label='Validación')
plt.xlabel('Número de Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.title('Loss de entrenamiento y el de validación (Caso A)')
plt.show()

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

# Obtener las predicciones del conjunto de entrenamiento
model_a.eval()
train_predictions = []
train_targets = []

with torch.no_grad():
    for data in dataloader1:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_a(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_predictions.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
conf_matrix_train_a = confusion_matrix(train_targets, train_predictions)
accuracy_train_a = accuracy_score(train_targets, train_predictions)

# Obtener las predicciones del conjunto de validación
val_predictions = []
val_targets = []
model_a.eval()
with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_a(inputs)
        _, predicted = torch.max(outputs.data, 1)
        val_predictions.extend(predicted.cpu().numpy())
        val_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de validación
conf_matrix_val_a = confusion_matrix(val_targets, val_predictions)
accuracy_val_a = accuracy_score(val_targets, val_predictions)

# Mostrar ambas matrices de confusión una al lado de la otra
fig, axs = plt.subplots(1, 2, figsize=(16, 6))

# Primera matriz de confusión (entrenamiento)
plot_confusion_matrix(conf_matrix_train_a, class_names=np.arange(10), ax=axs[0], title='Entrenamiento')

# Segunda matriz de confusión (validación)
plot_confusion_matrix(conf_matrix_val_a, class_names=np.arange(10), ax=axs[1], title='Validación')

# Ajustar la disposición de las subgráficos
plt.tight_layout()

plt.suptitle('Matriz de Confusión Normalizada (Caso A)', fontsize=12.5)

plt.show()

print('Normalización de Entrenamiento:', accuracy_train_a)
print('Normalización de Validación:', accuracy_val_a)

"""###Caso b"""

# Entrenamiento del modelo (b) con early stopping
start_time = time.time()

# Guardar resultados del loss y épocas que duró el entrenamiento
loss_train_b = []
loss_val_b = []
epochs_b = []

# Configurar early stopping con paciencia para el Modelo B
best_val_loss_b = float('inf')
max_epochs_b = 1000
early_stopping_patience_b = 10  # Número de epochs para esperar antes de detener el entrenamiento si el loss de validación aumenta

# ------------------Entrenamiento de la red por 1000 épocas para el Modelo B------------------ #
for epoch in range(max_epochs_b):

  # Guardar loss de cada batch para el Modelo B
  loss_train_batches_b = []
  loss_val_batches_b = []

  # ------------------Entrenamiento para el Modelo B------------------ #
  model_b.train()

  # Recorremos cada lote de los datos (batch) para el Modelo B
  for i, data in enumerate(dataloader1, 0):
      # Procesar batch actual
      inputs = data["features"].to(device)    # Características
      labels = data["labels"].to(device)      # Clases
      optimizer_b.zero_grad()                 # Poner a cero los gradientes de los parámetros
      # forward + backward + optimize
      outputs = model_b(inputs)               # Predicciones para el Modelo B
      loss_b = criterion_b(outputs, labels)   # Loss de entrenamiento para el Modelo B
      loss_b.backward()                       # Backpropagation
      optimizer_b.step()

      # La pérdida de entrenamiento en el batch actual para el Modelo B
      loss_train_batches_b.append(loss_b.item())

  # El loss de entrenamiento de la época actual para el Modelo B
  mean_train_loss_b = np.mean(loss_train_batches_b)
  loss_train_b.append(mean_train_loss_b) # Loss promedio de los batches para el Modelo B

  # ------------------Validación para el Modelo B------------------ #
  model_b.eval()

  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación para el Modelo B
    for i, data in enumerate(dataloader_val, 0):
        # batch actual
        inputs = data["features"].to(device)  # Características
        labels = data["labels"].to(device)    # Clases
        outputs = model_b(inputs)             # Obteniendo predicciones para el Modelo B

        # La pérdida de validación en el batch actual para el Modelo B
        loss_b = criterion_b(outputs, labels)
        loss_val_batches_b.append(loss_b.item())

  # El Loss de validación de la época actual para el Modelo B
  mean_val_loss_b = np.mean(loss_val_batches_b)
  loss_val_b.append(mean_val_loss_b)         # Loss promedio de los batches para el Modelo B

  # Guardar la época para el Modelo B
  epochs_b.append(epoch)

  # Verificar si el loss de validación está aumentando para el Modelo B
  if mean_val_loss_b < best_val_loss_b:
      best_val_loss_b = mean_val_loss_b
      patience_counter_b = 0  # Reiniciar el contador de paciencia para el Modelo B
  else:
      patience_counter_b += 1

  # Imprimir loss de entrenamiento y validación para el Modelo B
  print('Epoch %d: Training Loss: %.5f, Validation Loss: %.5f' % (epoch, mean_train_loss_b, mean_val_loss_b))

  # Detener si el loss de validación no mejora para el Modelo B
  if patience_counter_b >= early_stopping_patience_b:
      print('Detención anticipada debido al aumento de la pérdida de validación.')
      print('Early stopping at epoch for', epoch)
      break

end_time = time.time()
print('Finished Training (Caso B), total time: %.2f seconds' % (end_time-start_time))

# Graficar el loss de entrenamiento y validación en función del tiempo para el Modelo B
plt.figure(figsize=(10, 6))
plt.plot(epochs_b, loss_train_b, 'b', label='Entrenamiento')
plt.plot(epochs_b, loss_val_b, 'r', label='Validación')
plt.xlabel('Número de Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.title('Loss de entrenamiento y el de validación (Caso B)')
plt.show()

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

# Obtener las predicciones del conjunto de entrenamiento
model_b.eval()
train_predictions = []
train_targets = []

with torch.no_grad():
    for data in dataloader1:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_b(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_predictions.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
conf_matrix_train_b = confusion_matrix(train_targets, train_predictions)
accuracy_train_b = accuracy_score(train_targets, train_predictions)

# Obtener las predicciones del conjunto de validación
val_predictions = []
val_targets = []
model_b.eval()
with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_b(inputs)
        _, predicted = torch.max(outputs.data, 1)
        val_predictions.extend(predicted.cpu().numpy())
        val_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de validación
conf_matrix_val_b = confusion_matrix(val_targets, val_predictions)
accuracy_val_b = accuracy_score(val_targets, val_predictions)

# Mostrar ambas matrices de confusión una al lado de la otra
fig, axs = plt.subplots(1, 2, figsize=(16, 6))

# Primera matriz de confusión (entrenamiento)
plot_confusion_matrix(conf_matrix_train_b, class_names=np.arange(10), ax=axs[0], title='Entrenamiento')

# Segunda matriz de confusión (validación)
plot_confusion_matrix(conf_matrix_val_b, class_names=np.arange(10), ax=axs[1], title='Validación')

# Ajustar la disposición de las subgráficos
plt.tight_layout()

plt.suptitle('Matriz de Confusión Normalizada (Caso b)', fontsize=12.5)

plt.show()

print('Normalización de Entrenamiento:', accuracy_train_b)
print('Normalización de Validación:', accuracy_val_b)

"""###Caso c"""

# Entrenamiento del modelo (C) con early stopping
start_time = time.time()

# Guardar resultados del loss y épocas que duró el entrenamiento
loss_train_c = []
loss_val_c = []
epochs_c = []

# Configurar early stopping con paciencia para el Modelo C
best_val_loss_c = float('inf')
max_epochs_c = 1000
early_stopping_patience_c = 10  # Número de epochs para esperar antes de detener el entrenamiento si el loss de validación aumenta

# ------------------Entrenamiento de la red por 1000 épocas para el Modelo C------------------ #
for epoch in range(max_epochs_c):

  # Guardar loss de cada batch para el Modelo C
  loss_train_batches_c = []
  loss_val_batches_c = []

  # ------------------Entrenamiento para el Modelo C------------------ #
  model_c.train()

  # Recorremos cada lote de los datos (batch) para el Modelo C
  for i, data in enumerate(dataloader1, 0):
      # Procesar batch actual
      inputs = data["features"].to(device)    # Características
      labels = data["labels"].to(device)      # Clases
      optimizer_c.zero_grad()                 # Poner a cero los gradientes de los parámetros
      # forward + backward + optimize
      outputs = model_c(inputs)               # Predicciones para el Modelo C
      loss_c = criterion_c(outputs, labels)   # Loss de entrenamiento para el Modelo C
      loss_c.backward()                       # Backpropagation
      optimizer_c.step()

      # La pérdida de entrenamiento en el batch actual para el Modelo C
      loss_train_batches_c.append(loss_c.item())

  # El loss de entrenamiento de la época actual para el Modelo C
  mean_train_loss_c = np.mean(loss_train_batches_c)
  loss_train_c.append(mean_train_loss_c) # Loss promedio de los batches para el Modelo C

  # ------------------Validación para el Modelo C------------------ #
  model_c.eval()

  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación para el Modelo C
    for i, data in enumerate(dataloader_val, 0):
        # batch actual
        inputs = data["features"].to(device)  # Características
        labels = data["labels"].to(device)    # Clases
        outputs = model_c(inputs)             # Obteniendo predicciones para el Modelo C

        # La pérdida de validación en el batch actual para el Modelo C
        loss_c = criterion_c(outputs, labels)
        loss_val_batches_c.append(loss_c.item())

  # El Loss de validación de la época actual para el Modelo C
  mean_val_loss_c = np.mean(loss_val_batches_c)
  loss_val_c.append(mean_val_loss_c)         # Loss promedio de los batches para el Modelo C

  # Guardar la época para el Modelo C
  epochs_c.append(epoch)

  # Verificar si el loss de validación está aumentando para el Modelo C
  if mean_val_loss_c < best_val_loss_c:
      best_val_loss_c = mean_val_loss_c
      patience_counter_c = 0  # Reiniciar el contador de paciencia para el Modelo C
  else:
      patience_counter_c += 1

  # Imprimir loss de entrenamiento y validación para el Modelo C
  print('Epoch %d: Training Loss: %.5f, Validation Loss: %.5f' % (epoch, mean_train_loss_c, mean_val_loss_c))

  # Detener si el loss de validación no mejora para el Modelo C
  if patience_counter_c >= early_stopping_patience_c:
      print('Detención anticipada debido al aumento de la pérdida de validación.')
      print('Early stopping at epoch', epoch)
      break

end_time = time.time()
print('Finished Training (Modelo C), total time: %.2f seconds' % (end_time-start_time))

# Graficar el loss de entrenamiento y validación en función del tiempo para el Modelo C
plt.figure(figsize=(10, 6))
plt.plot(epochs_c, loss_train_c, 'b', label='Entrenamiento')
plt.plot(epochs_c, loss_val_c, 'r', label='Validación')
plt.xlabel('Número de Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.title('Loss de entrenamiento y el de validación (Caso C)')
plt.show()

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

# Obtener las predicciones del conjunto de entrenamiento
model_c.eval()
train_predictions = []
train_targets = []

with torch.no_grad():
    for data in dataloader1:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_c(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_predictions.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
conf_matrix_train_c = confusion_matrix(train_targets, train_predictions)
accuracy_train_c = accuracy_score(train_targets, train_predictions)

# Obtener las predicciones del conjunto de validación
val_predictions = []
val_targets = []
model_c.eval()
with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_c(inputs)
        _, predicted = torch.max(outputs.data, 1)
        val_predictions.extend(predicted.cpu().numpy())
        val_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de validación
conf_matrix_val_c = confusion_matrix(val_targets, val_predictions)
accuracy_val_c = accuracy_score(val_targets, val_predictions)

# Mostrar ambas matrices de confusión una al lado de la otra
fig, axs = plt.subplots(1, 2, figsize=(16, 6))

# Primera matriz de confusión (entrenamiento)
plot_confusion_matrix(conf_matrix_train_c, class_names=np.arange(10), ax=axs[0], title='Entrenamiento')

# Segunda matriz de confusión (validación)
plot_confusion_matrix(conf_matrix_val_c, class_names=np.arange(10), ax=axs[1], title='Validación')

# Ajustar la disposición de las subgráficos
plt.tight_layout()

plt.suptitle('Matriz de Confusión Normalizada (Caso C)', fontsize=12.5)

plt.show()

print('Normalización de Entrenamiento:', accuracy_train_c)
print('Normalización de Validación:', accuracy_val_c)

"""###Caso d"""

# Entrenamiento del modelo (D) con early stopping
start_time = time.time()

# Guardar resultados del loss y épocas que duró el entrenamiento
loss_train_d = []
loss_val_d = []
epochs_d = []

# Configurar early stopping con paciencia para el Modelo D
best_val_loss_d = float('inf')
max_epochs_d = 1000
early_stopping_patience_d = 10  # Número de epochs para esperar antes de detener el entrenamiento si el loss de validación aumenta

# ------------------Entrenamiento de la red por 1000 épocas para el Modelo D------------------ #
for epoch in range(max_epochs_d):

  # Guardar loss de cada batch para el Modelo D
  loss_train_batches_d = []
  loss_val_batches_d = []

  # ------------------Entrenamiento para el Modelo D------------------ #
  model_d.train()

  # Recorremos cada lote de los datos (batch) para el Modelo D
  for i, data in enumerate(dataloader1, 0):
      # Procesar batch actual
      inputs = data["features"].to(device)    # Características
      labels = data["labels"].to(device)      # Clases
      optimizer_d.zero_grad()                 # Poner a cero los gradientes de los parámetros
      # forward + backward + optimize
      outputs = model_d(inputs)               # Predicciones para el Modelo D
      loss_d = criterion_d(outputs, labels)   # Loss de entrenamiento para el Modelo D
      loss_d.backward()                       # Backpropagation
      optimizer_d.step()

      # La pérdida de entrenamiento en el batch actual para el Modelo D
      loss_train_batches_d.append(loss_d.item())

  # El loss de entrenamiento de la época actual para el Modelo D
  mean_train_loss_d = np.mean(loss_train_batches_d)
  loss_train_d.append(mean_train_loss_d) # Loss promedio de los batches para el Modelo D

  # ------------------Validación para el Modelo D------------------ #
  model_d.eval()

  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación para el Modelo D
    for i, data in enumerate(dataloader_val, 0):
        # batch actual
        inputs = data["features"].to(device)  # Características
        labels = data["labels"].to(device)    # Clases
        outputs = model_d(inputs)             # Obteniendo predicciones para el Modelo D

        # La pérdida de validación en el batch actual para el Modelo D
        loss_d = criterion_d(outputs, labels)
        loss_val_batches_d.append(loss_d.item())

  # El Loss de validación de la época actual para el Modelo D
  mean_val_loss_d = np.mean(loss_val_batches_d)
  loss_val_d.append(mean_val_loss_d)         # Loss promedio de los batches para el Modelo D

  # Guardar la época para el Modelo D
  epochs_d.append(epoch)

  # Verificar si el loss de validación está aumentando para el Modelo D
  if mean_val_loss_d < best_val_loss_d:
      best_val_loss_d = mean_val_loss_d
      patience_counter_d = 0  # Reiniciar el contador de paciencia para el Modelo D
  else:
      patience_counter_d += 1

  # Imprimir loss de entrenamiento y validación para el Modelo D
  print('Epoch %d: Training Loss: %.5f, Validation Loss: %.5f' % (epoch, mean_train_loss_d, mean_val_loss_d))

  # Detener si el loss de validación no mejora para el Modelo D
  if patience_counter_d >= early_stopping_patience_d:
      print('Detención anticipada debido al aumento de la pérdida de validación.')
      print('Early stopping at epoch', epoch)
      break

end_time = time.time()
print('Finished Training (Caso D), total time: %.2f seconds' % (end_time-start_time))

# Graficar el loss de entrenamiento y validación en función del tiempo para el Modelo D
plt.figure(figsize=(10, 6))
plt.plot(epochs_d, loss_train_d, 'b', label='Entrenamiento')
plt.plot(epochs_d, loss_val_d, 'r', label='Validación')
plt.xlabel('Número de Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.title('Loss de entrenamiento y el de validación (Caso D)')
plt.show()

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

# Obtener las predicciones del conjunto de entrenamiento
model_d.eval()
train_predictions = []
train_targets = []

with torch.no_grad():
    for data in dataloader1:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_d(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_predictions.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
conf_matrix_train_d = confusion_matrix(train_targets, train_predictions)
accuracy_train_d = accuracy_score(train_targets, train_predictions)

# Obtener las predicciones del conjunto de validación
val_predictions = []
val_targets = []
model_d.eval()
with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_d(inputs)
        _, predicted = torch.max(outputs.data, 1)
        val_predictions.extend(predicted.cpu().numpy())
        val_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de validación
conf_matrix_val_d = confusion_matrix(val_targets, val_predictions)
accuracy_val_d = accuracy_score(val_targets, val_predictions)

# Mostrar ambas matrices de confusión una al lado de la otra
fig, axs = plt.subplots(1, 2, figsize=(16, 6))

# Primera matriz de confusión (entrenamiento)
plot_confusion_matrix(conf_matrix_train_d, class_names=np.arange(10), ax=axs[0], title='Entrenamiento')

# Segunda matriz de confusión (validación)
plot_confusion_matrix(conf_matrix_val_d, class_names=np.arange(10), ax=axs[1], title='Validación')

# Ajustar la disposición de las subgráficos
plt.tight_layout()

plt.suptitle('Matriz de Confusión Normalizada (Caso D)', fontsize=12.5)

plt.show()

print('Normalización de Entrenamiento:', accuracy_train_d)
print('Normalización de Validación:', accuracy_val_d)

"""###Caso e"""

# Entrenamiento del modelo (E) con early stopping
start_time = time.time()

# Guardar resultados del loss y épocas que duró el entrenamiento para el Modelo E
loss_train_e = []
loss_val_e = []
epochs_e = []

# Configurar early stopping con paciencia para el Modelo E
best_val_loss_e = float('inf')
max_epochs_e = 1000
early_stopping_patience_e = 10  # Número de epochs para esperar antes de detener el entrenamiento si el loss de validación aumenta

# ------------------Entrenamiento de la red por 1000 épocas para el Modelo E------------------ #
for epoch in range(max_epochs_e):

  # Guardar loss de cada batch para el Modelo E
  loss_train_batches_e = []
  loss_val_batches_e = []

  # ------------------Entrenamiento para el Modelo E------------------ #
  model_e.train()

  # Recorremos cada lote de los datos (batch) para el Modelo E
  for i, data in enumerate(dataloader1, 0):
      # Procesar batch actual
      inputs = data["features"].to(device)    # Características
      labels = data["labels"].to(device)      # Clases
      optimizer_e.zero_grad()                 # Poner a cero los gradientes de los parámetros
      # forward + backward + optimize
      outputs = model_e(inputs)               # Predicciones para el Modelo E
      loss_e = criterion_e(outputs, labels)   # Loss de entrenamiento para el Modelo E
      loss_e.backward()                       # Backpropagation
      optimizer_e.step()

      # La pérdida de entrenamiento en el batch actual para el Modelo E
      loss_train_batches_e.append(loss_e.item())

  # El loss de entrenamiento de la época actual para el Modelo E
  mean_train_loss_e = np.mean(loss_train_batches_e)
  loss_train_e.append(mean_train_loss_e) # Loss promedio de los batches para el Modelo E

  # ------------------Validación para el Modelo E------------------ #
  model_e.eval()

  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación para el Modelo E
    for i, data in enumerate(dataloader_val, 0):
        # batch actual
        inputs = data["features"].to(device)  # Características
        labels = data["labels"].to(device)    # Clases
        outputs = model_e(inputs)             # Obteniendo predicciones para el Modelo E

        # La pérdida de validación en el batch actual para el Modelo E
        loss_e = criterion_e(outputs, labels)
        loss_val_batches_e.append(loss_e.item())

  # El Loss de validación de la época actual para el Modelo E
  mean_val_loss_e = np.mean(loss_val_batches_e)
  loss_val_e.append(mean_val_loss_e)         # Loss promedio de los batches para el Modelo E

  # Guardar la época para el Modelo E
  epochs_e.append(epoch)

  # Verificar si el loss de validación está aumentando para el Modelo E
  if mean_val_loss_e < best_val_loss_e:
      best_val_loss_e = mean_val_loss_e
      patience_counter_e = 0  # Reiniciar el contador de paciencia para el Modelo E
  else:
      patience_counter_e += 1

  # Imprimir loss de entrenamiento y validación para el Modelo E
  print('Epoch %d: Training Loss: %.5f, Validation Loss: %.5f' % (epoch, mean_train_loss_e, mean_val_loss_e))

  # Detener si el loss de validación no mejora para el Modelo E
  if patience_counter_e >= early_stopping_patience_e:
      print('Detención anticipada debido al aumento de la pérdida de validación.')
      print('Early stopping at epoch', epoch)
      break

end_time = time.time()
print('Finished Training (Caso E), total time: %.2f seconds' % (end_time-start_time))

# Graficar el loss de entrenamiento y validación en función del tiempo para el Modelo E
plt.figure(figsize=(10, 6))
plt.plot(epochs_e, loss_train_e, 'b', label='Entrenamiento')
plt.plot(epochs_e, loss_val_e, 'r', label='Validación')
plt.xlabel('Número de Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.title('Loss de entrenamiento y el de validación (Caso E)')
plt.show()

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

# Obtener las predicciones del conjunto de entrenamiento
model_e.eval()
train_predictions = []
train_targets = []

with torch.no_grad():
    for data in dataloader1:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_e(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_predictions.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
conf_matrix_train_e = confusion_matrix(train_targets, train_predictions)
accuracy_train_e = accuracy_score(train_targets, train_predictions)

# Obtener las predicciones del conjunto de validación
val_predictions = []
val_targets = []
model_e.eval()
with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_e(inputs)
        _, predicted = torch.max(outputs.data, 1)
        val_predictions.extend(predicted.cpu().numpy())
        val_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de validación
conf_matrix_val_e = confusion_matrix(val_targets, val_predictions)
accuracy_val_e = accuracy_score(val_targets, val_predictions)

# Mostrar ambas matrices de confusión una al lado de la otra
fig, axs = plt.subplots(1, 2, figsize=(16, 6))

# Primera matriz de confusión (entrenamiento)
plot_confusion_matrix(conf_matrix_train_e, class_names=np.arange(10), ax=axs[0], title='Entrenamiento')

# Segunda matriz de confusión (validación)
plot_confusion_matrix(conf_matrix_val_e, class_names=np.arange(10), ax=axs[1], title='Validación')

# Ajustar la disposición de las subgráficos
plt.tight_layout()

plt.suptitle('Matriz de Confusión Normalizada (Caso E)', fontsize=12.5)

plt.show()

print('Normalización de Entrenamiento:', accuracy_train_e)
print('Normalización de Validación:', accuracy_val_e)

"""###Caso f"""

# Entrenamiento del modelo (F) con early stopping
start_time = time.time()

# Guardar resultados del loss y épocas que duró el entrenamiento para el Modelo F
loss_train_f = []
loss_val_f = []
epochs_f = []

# Configurar early stopping con paciencia para el Modelo F
best_val_loss_f = float('inf')
max_epochs_f = 1000
early_stopping_patience_f = 10  # Número de epochs para esperar antes de detener el entrenamiento si el loss de validación aumenta

# ------------------Entrenamiento de la red por 1000 épocas para el Modelo F------------------ #
for epoch in range(max_epochs_f):

  # Guardar loss de cada batch para el Modelo F
  loss_train_batches_f = []
  loss_val_batches_f = []

  # ------------------Entrenamiento para el Modelo F------------------ #
  model_f.train()

  # Recorremos cada lote de los datos (batch) para el Modelo F
  for i, data in enumerate(dataloader1, 0):
      # Procesar batch actual
      inputs = data["features"].to(device)    # Características
      labels = data["labels"].to(device)      # Clases
      optimizer_f.zero_grad()                 # Poner a cero los gradientes de los parámetros
      # forward + backward + optimize
      outputs = model_f(inputs)               # Predicciones para el Modelo F
      loss_f = criterion_f(outputs, labels)   # Loss de entrenamiento para el Modelo F
      loss_f.backward()                       # Backpropagation
      optimizer_f.step()

      # La pérdida de entrenamiento en el batch actual para el Modelo F
      loss_train_batches_f.append(loss_f.item())

  # El loss de entrenamiento de la época actual para el Modelo F
  mean_train_loss_f = np.mean(loss_train_batches_f)
  loss_train_f.append(mean_train_loss_f) # Loss promedio de los batches para el Modelo F

  # ------------------Validación para el Modelo F------------------ #
  model_f.eval()

  with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación para el Modelo F
    for i, data in enumerate(dataloader_val, 0):
        # batch actual
        inputs = data["features"].to(device)  # Características
        labels = data["labels"].to(device)    # Clases
        outputs = model_f(inputs)             # Obteniendo predicciones para el Modelo F

        # La pérdida de validación en el batch actual para el Modelo F
        loss_f = criterion_f(outputs, labels)
        loss_val_batches_f.append(loss_f.item())

  # El Loss de validación de la época actual para el Modelo F
  mean_val_loss_f = np.mean(loss_val_batches_f)
  loss_val_f.append(mean_val_loss_f)         # Loss promedio de los batches para el Modelo F

  # Guardar la época para el Modelo F
  epochs_f.append(epoch)

  # Verificar si el loss de validación está aumentando para el Modelo F
  if mean_val_loss_f < best_val_loss_f:
      best_val_loss_f = mean_val_loss_f
      patience_counter_f = 0  # Reiniciar el contador de paciencia para el Modelo F
  else:
      patience_counter_f += 1

  # Imprimir loss de entrenamiento y validación para el Modelo F
  print('Epoch %d: Training Loss: %.5f, Validation Loss: %.5f' % (epoch, mean_train_loss_f, mean_val_loss_f))

  # Detener si el loss de validación no mejora para el Modelo F
  if patience_counter_f >= early_stopping_patience_f:
      print('Detención anticipada debido al aumento de la pérdida de validación.')
      print('Early stopping at epoch', epoch)
      break

end_time = time.time()
print('Finished Training (Caso F), total time: %.2f seconds' % (end_time-start_time))

# Graficar el loss de entrenamiento y validación en función del tiempo para el Modelo F
plt.figure(figsize=(10, 6))
plt.plot(epochs_f, loss_train_f, 'b', label='Entrenamiento')
plt.plot(epochs_f, loss_val_f, 'r', label='Validación')
plt.xlabel('Número de Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.title('Loss de entrenamiento y el de validación (Caso F)')
plt.show()

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

# Obtener las predicciones del conjunto de entrenamiento
model_f.eval()
train_predictions = []
train_targets = []

with torch.no_grad():
    for data in dataloader1:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_f(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_predictions.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
conf_matrix_train_f = confusion_matrix(train_targets, train_predictions)
accuracy_train_f = accuracy_score(train_targets, train_predictions)

# Obtener las predicciones del conjunto de validación
val_predictions = []
val_targets = []
model_f.eval()
with torch.no_grad():
    for data in dataloader_val:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_f(inputs)
        _, predicted = torch.max(outputs.data, 1)
        val_predictions.extend(predicted.cpu().numpy())
        val_targets.extend(labels.cpu().numpy())

# Calcular la matriz de confusión para el conjunto de validación
conf_matrix_val_f = confusion_matrix(val_targets, val_predictions)
accuracy_val_f = accuracy_score(val_targets, val_predictions)

# Mostrar ambas matrices de confusión una al lado de la otra
fig, axs = plt.subplots(1, 2, figsize=(16, 6))

# Primera matriz de confusión (entrenamiento)
plot_confusion_matrix(conf_matrix_train_f, class_names=np.arange(10), ax=axs[0], title='Entrenamiento')

# Segunda matriz de confusión (validación)
plot_confusion_matrix(conf_matrix_val_f, class_names=np.arange(10), ax=axs[1], title='Validación')

# Ajustar la disposición de las subgráficos
plt.tight_layout()

plt.suptitle('Matriz de Confusión Normalizada (Caso F)', fontsize=12.5)

plt.show()

print('Normalización de Entrenamiento:', accuracy_train_f)
print('Normalización de Validación:', accuracy_val_f)

"""##P3"""

# Definir la función para mostrar la matriz de confusión con colores
def plot_confusion_matrix(conf_matrix, class_names, normalize=True, ax=None, title=None):
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 7))
    else:
        fig = ax.get_figure()

    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)
    if title:
        ax.set_title(title)
    ax.set_xlabel('Predicción')
    ax.set_ylabel('Valor Real')

best_val_accuracy = 0.0  # Inicializa la mejor precisión en validación
best_modelo = None  # Inicializa el mejor modelo

# Diccionario que almacena los modelos correspondientes a cada caso
models = {
    'a': model_a,
    'b': model_b,
    'c': model_c,
    'd': model_d,
    'e': model_e,
    'f': model_f,
}
# Almacena las métricas de precisión de validación para cada caso
val_accuracy_dict = {
    'a': accuracy_val_a,
    'b': accuracy_val_b,
    'c': accuracy_val_c,
    'd': accuracy_val_d,
    'e': accuracy_val_e,
    'f': accuracy_val_f,
}

# Encuentra el modelo con la mejor precisión en validación
for model, val_accuracy in val_accuracy_dict.items():
    if val_accuracy > best_val_accuracy:
        best_val_accuracy = val_accuracy
        best_modelo = model

# Carga el modelo correspondiente al mejor modelo
best_test_model = models[best_modelo]

# Realiza las mismas operaciones para calcular la matriz de confusión en el conjunto de prueba
test_preds = []
test_labels = []

with torch.no_grad():
    for data in dataloader2:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = best_test_model(inputs)
        test_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        test_labels.extend(labels.cpu().numpy())

# Calcula la matriz de confusión en el conjunto de prueba
test_confusion = confusion_matrix(test_labels, test_preds, normalize='true')
test_accuracy = accuracy_score(test_labels, test_preds)

# Mostrar la matriz de confusión
fig, axs = plt.subplots(figsize=(8, 6))

# Matriz de confusión (prueba)
plot_confusion_matrix(test_confusion, class_names=np.arange(10), ax=axs, title=f'Matriz de Confusión Normalizada del conjunto prueba\n Mejor modelo (Caso {best_modelo})')

# Ajustar la disposición de las subgráficos
plt.tight_layout()
plt.show()
print('Normalización de Prueba:', test_accuracy)